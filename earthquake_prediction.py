# -*- coding: utf-8 -*-
"""Earthquake_Prediction

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1trJfPc6VVy3HEUKvLDyokzuFp7pCg6av
"""

import pandas as pd
import numpy as np
from matplotlib import pyplot as plt

from google.colab import files
uploaded = files.upload()

# Store the uploaded file into the dataframe
import io

dataset = pd.read_csv(io.BytesIO(uploaded['database.csv']))

dataset.head()

#We convert time into a generalisd format for computation
import datetime
import time

timestamp = []
for d, t in zip(dataset['Date'], dataset['Time']):
    try:
        ts = datetime.datetime.strptime(d+' '+t, '%m/%d/%Y %H:%M:%S')
        timestamp.append(time.mktime(ts.timetuple()))
    except ValueError:
        # print('ValueError')
        timestamp.append('ValueError')

timeStamp = pd.Series(timestamp)
dataset['Timestamp'] = timeStamp.values

dataset_new = dataset.drop(['Date', 'Time'], axis=1)
dataset_new = dataset_new[dataset_new.Timestamp != 'ValueError']
dataset_new.head()

dataset.isnull().sum()

!apt-get install libgeos-3.5.0
!apt-get install libgeos-dev
!pip install https://github.com/matplotlib/basemap/archive/master.zip

from mpl_toolkits.basemap import Basemap

m = Basemap(projection='mill',llcrnrlat=-80,urcrnrlat=80, llcrnrlon=-180,urcrnrlon=180,lat_ts=20,resolution='c')

longitudes = dataset["Longitude"].tolist()
latitudes = dataset["Latitude"].tolist()
#m = Basemap(width=12000000,height=9000000,projection='lcc',
            #resolution=None,lat_1=80.,lat_2=55,lat_0=80,lon_0=-107.)
x,y = m(longitudes,latitudes)

fig = plt.figure(figsize=(12,10))
plt.title("All affected areas")
m.plot(x, y, "o", markersize = 2, color = 'blue')
m.drawcoastlines()
m.fillcontinents(color='coral',lake_color='aqua')
m.drawmapboundary()
m.drawcountries()
plt.show()

X = dataset_new[['Timestamp', 'Latitude', 'Longitude']]
y = dataset_new[['Magnitude', 'Depth']]

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)
print(X_train.shape, X_test.shape, y_train.shape, X_test.shape)



from sklearn.ensemble import RandomForestRegressor

regressor = RandomForestRegressor(random_state=10)
regressor.fit(X_train, y_train)
regressor.predict(X_test)

regressor.score(X_test, y_test)

from sklearn.model_selection import GridSearchCV

parameters = {'n_estimators':[10, 20, 50, 100, 200, 500]}

grid_obj = GridSearchCV(regressor, parameters)
grid_fit = grid_obj.fit(X_train, y_train)
best_fit = grid_fit.best_estimator_
best_fit.predict(X_test)

best_fit

best_fit.score(X_test,y_test)